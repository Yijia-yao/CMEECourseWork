#  Week 1: Computing Foundations

Welcome to Week 1 of CMEE coursework! 🎉  
This week was all about learning the essential computing tools used in scientific programming and research.  
It started from the very basics — working with the terminal — and gradually moved towards scripting, version control, and scientific writing using LaTeX.

This README is my personal record of what I learned, the commands I used, and how everything fits together.  
Hopefully future me will thank current me for writing this 😆

---

## 🗂️ Folder Structure

Here’s the main folder structure I set up for Week 1:


Week1/

├── Code/

│ ├── Bash and UNIX exercises

│ ├── Python scripts

│ ├── R scripts

│ └── LaTeX examples

├── Data/

│ └── Example datasets used in exercises

├── Results/

│ └── Output files generated by scripts

└── Sandbox/

└── Experimental and test scripts

---


Each directory has a clear role:
- `code/` → where I store reusable scripts  
- `data/` → all datasets (never modified directly!)  
- `results/` → cleaned data, plots, or processed files  
- `sandbox/` → a “playground” for testing commands before using them in real scripts  

---

# 1. UNIX and Linux

The first part of Week 1 introduced the **UNIX shell** — the command-line interface that talks directly to the operating system.  
We used it to navigate folders, manage files, and even analyze biological data.

### Basic Commands I Practiced

| Command | Description |
|----------|--------------|
| `pwd` | Shows the current directory |
| `ls -lh` | Lists files (human-readable format) |
| `cd` | Changes directory |
| `mkdir foldername` | Creates a new directory |
| `cp file1 file2` | Copies a file |
| `mv oldname newname` | Renames or moves a file |
| `rm filename` | Deletes a file |
| `wc -l filename` | Counts lines in a file |
| `head` / `tail` | Shows the first / last few lines |
| `grep "pattern" file` | Searches for a string |
| `cut`, `sort`, `uniq` | Useful for data extraction |
| `cat file1 file2 > merged.txt` | Concatenates files |

---

### Practical Example: FASTA Files

We worked with DNA sequence files in `.fasta` format.

Example: Sequence_1
ATGCGTACGTAGCTAGCTAGCT


#### Tasks I did with shell commands:
- Count how many sequences are in a file  
  ```bash
  grep -c ">" *.fasta

- Calculate GC content (percentage of G and C)
 ```bash
 grep -v ">" sequence.fasta | tr -d "\n" | grep -o "[GC]" | wc -l
 ```

 - Extract sequence names only
 ```bash
grep ">" sequence.fasta | cut -d ">" -f2
```

Doing this with just shell commands was surprisingly powerful — no R or Python needed!

---
# 2. Shell Scripting

Once I was comfortable running individual commands, we started automating them using shell scripts.
This allows repeating workflows quickly and consistently.

### What Is a Shell Script?

A shell script is just a text file (usually ending with .sh) that contains a list of commands.
It’s executed line by line by the shell.

Example structure:
```bash
#!/bin/bash
# Author: Yijia Yao
# Script: boilerplate.sh
# Desc: Simple demo script
# Date: Oct 2025
echo "This is a shell script!"
```

### Basic Conventions

Always start with the shebang line: 
#!/bin/bash

Use # for comments and documentation

Variable names are usually in UPPERCASE

No spaces around = when assigning variables

`MY_VAR=value `     （   correct   ）

`MY_VAR = value `        （ wrong ）

### Running Scripts

There are two ways to run a script:
```bash
bash myscript.sh
```
or
```bash
chmod +x myscript.sh
./myscript.sh
```
The second method makes it executable, so you can run it like a command.

### Variables in Shell Scripts

Types of Variables:

(1) Special variables (automatically set by the shell)

- `$0` – script name

- `$1`, `$2`, ... – command line arguments

- `$#`– number of arguments

- `$@` – all arguments

（2）User-defined variables

- `MY_VAR="Hello"`

- `read USER_INPUT` – take user input

- `RESULT=$(command)` – assign command output to a variable

### Example Scripts I Wrote

`variables.sh`

Demonstrates how to use different types of variables:
```bash
#!/bin/bash
echo "This script was called with $# arguments"
echo "First arg: $1, Second arg: $2"

MY_VAR='some string'
echo "Value: $MY_VAR"

echo "Enter two numbers:"
read a b
SUM=$(expr $a + $b)
echo "Their sum is: $SUM"
```
---

`tabtocsv.sh`

Converts a tab-delimited file to a CSV:
```bash
#!/bin/bash
# Converts tabs to commas
echo "Creating a comma-delimited version of $1 ..."
cat $1 | tr -s "\t" "," > $1.csv
echo "Done!"
```
---

`CountLines.sh`

Counts the number of lines in a file:
```bash
#!/bin/bash
NumLines=$(wc -l < $1)
echo "The file $1 has $NumLines lines."
```

### Common Directories Used in Scripts
| Folder | Purpose |
|----------|--------------|
| `code/` | where `.sh` scripts live |
| `data/` | stores raw input files|
| `results/` | where processed files are saved |
| `sandbox/` | for testing temporary commands |

I often use relative paths like ` ../data/ ` or ` ../results/ ` to navigate between them.

---

### 1️⃣ `boilerplate.sh`
A basic template for writing scripts.  
It includes the author name, date, description, and a structure for adding commands later.  
This helped me standardize all my scripts.

**Run:**
```bash
bash boilerplate.sh
```
### 2️⃣ `variables.sh`

Introduced the concept of variables, user input, and argument handling.
```bash
bash variables.sh arg1 arg2
```
### 3️⃣ MyExampleScript.sh & myscript.sh

These were early test scripts used to practice printing messages, running basic commands, and understanding the flow of a Bash script.

```bash
bash MyExampleScript.sh
```
### 4️⃣ CountLines.sh

Counts how many lines a file contains using wc -l.
It taught me how to use file arguments in scripts and how to pass them safely.
```bash
bash CountLines.sh ../Data/filename.txt
```
### 5️⃣ tabtocsv.sh

Replaces all tabs in a .txt file with commas and saves it as .csv.
It also checks if the correct number of inputs is provided before running.
```bash
bash tabtocsv.sh ../Data/input.txt
```
Output:
`input.csv`

### 6️⃣ csvtospace.sh

Does the opposite of tabtocsv.sh:
converts comma-separated .csv files into space-separated ones without overwriting the original.

```bash
bash csvtospace.sh ../Data/input.csv
```

### 7️⃣ ConcatenateTwoFiles.sh

Joins two files together into a new one, after checking that both exist.
A simple but useful way to combine data files quickly.
```bash
bash ConcatenateTwoFiles.sh file1.txt file2.txt
```

### 8️⃣ tiff2png.sh

Loops through a folder and converts `.tif` images into `.png` format.
It uses a `for` loop and an external image conversion command.

```bash tiff2png.sh```

### 9️⃣ UnixPrac1.txt

This is not a script but a record of UNIX command exercises.
It includes commands like `ls`, `grep`, `wc`, and `sort`, and explains what each does.


# 3.Version Control with Git
Version control helps track changes, recover older versions, and collaborate smoothly.

### Basic Git Workflow
```bash
git init                   # create new repository
git status                 # check what's changed
git add filename           # stage files
git commit -m "message"    # save snapshot
git log                    # view history
git remote add origin ...  # link to GitHub repo
git push origin main       # upload to GitHub
```
I created a new GitHub repo called CMEECourseWork, then linked my local folder using:
```bash
git remote add origin https://github.com/YijiaYao/CMEECourseWork.git
git push -u origin main
```
### Ignore Unwanted Files
I made a `.gitignore` file to exclude temporary outputs:
```bash
*.log
*.aux
*.blg
*.csv
sandbox/
```
This keeps the repository clean and lightweight.

---

# 4.Scientific Documents with LaTeX
We ended the week learning how to write scientific papers using LaTeX, instead of Word.

---
### Basic Structure of a `.tex` File
```latex
\documentclass[12pt]{article}
\title{A Simple Document}
\author{Yijia Yao}
\date{}
\begin{document}
  \maketitle

  \section{Introduction}
  This is my first LaTeX document!

  \section{Methods}
  Here’s an equation:
  \begin{equation}
    \frac{dN}{dt} = rN(1 - \frac{N}{K})
  \end{equation}

\end{document}
```

### Useful Environments
| Environment      |      Purpose |
|----------|--------------|
| `itemize` | Bullet lists |
| `enumerate` | Numbered lists|
| `figure` | Add figures |
| `table` | Display tables |
| `equation` | Math equations |
| `center` | Center text or objects |

### Bibliography with BibTeX
(1) Create a .bib file:
```bibtex
@article{verhulst1838notice,
  title={Notice sur la loi que la population suit dans son accroissement},
  author={Verhulst, Pierre-François},
  journal={Corresp. Math. Phys.},
  volume={10},
  pages={113--126},
  year={1838}
}
```
(2)Compile
```bash
pdflatex FirstExample.tex
bibtex FirstExample
pdflatex FirstExample.tex
pdflatex FirstExample.tex
```
### Automating Compilation with a Script
Created a helper script `CompileLaTeX.sh`:
```bash
#!/bin/bash
pdflatex $1.tex
bibtex $1
pdflatex $1.tex
pdflatex $1.tex
evince $1.pdf &
rm *.aux *.log *.bbl *.blg
```
Now I just run:
```bash
bash CompileLaTeX.sh FirstExample
```
and it compiles + cleans everything automatically.

---

# Reflection

Week 1 was a crash course in computational foundations.
I learned how to:

- Use the UNIX shell effectively

- Automate tasks with shell scripts

- Manage and track work with Git

- Write clean scientific documents using LaTeX

Each `.sh` script in `/Code` demonstrates one key concept:
- **boilerplate.sh** – structure of a shell script  
- **variables.sh** – handling and passing variables  
- **tabtocsv.sh** – text processing with `tr`  
- **CountLines.sh** – file line counting  
- **ConcatenateTwoFiles.sh** – merging files  
- **tiff2png.sh** – image format conversion  
- **CompileLaTeX.sh** – automating LaTeX compilation  

All outputs are stored in `/Results`.  
Temporary experiments are saved in `/Sandbox`.


Now I have a proper workflow — from command-line data handling → automated scripting → version tracking → formatted output.
It’s starting to feel like real computational science

---


Author: Yijia Yao

Email: yijia.yao25@imperial.ac.uk

Course: MSc Computational Methods in Ecology and Evolution

Date: Week 1